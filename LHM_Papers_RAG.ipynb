{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5526386f-500f-43c6-a545-cdca4ab69774",
   "metadata": {},
   "source": [
    "# RAG Implementation using Llama-3 model\n",
    "\n",
    "This is a simple RAG implementation using all-mpnet-base-v2 embedding model, chromadb vector database and Llama-3 8B model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9485b347-af60-4227-9d34-0cb0932b83ea",
   "metadata": {},
   "source": [
    "Note: Download pytorch with CUDA to use GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ec68e36-20ec-406a-9a52-aabdaf49462b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\justinfz\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForCausalLM, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import os\n",
    "from pdfminer.high_level import extract_text\n",
    "import time\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2835361-2e51-490c-ac86-f605038190b1",
   "metadata": {},
   "source": [
    "## Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0e310e2-3fdf-48ee-827f-b9b29090ca56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\justinfz\\AppData\\Local\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "embedding_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "chroma_client = chromadb.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b492341b-2152-4d82-ae73-dcf2ff06d5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8254a1f34e14767b5a6d8526eacdb9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bbed74c-7776-407b-9dc5-4bb90c9cec69",
   "metadata": {},
   "outputs": [],
   "source": [
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]\n",
    "def get_llama3_chat_reponse(messages):\n",
    "    input_ids = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    return_tensors=\"pt\").to(model.device)\n",
    "    outputs = model.generate(\n",
    "    input_ids,\n",
    "    max_new_tokens=500,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    temperature=0.0001,\n",
    "    top_p=0.9,)\n",
    "    response = outputs[0][input_ids.shape[-1]:]\n",
    "    return (tokenizer.decode(response, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5198cf8-6d97-4fd1-af09-faad35581eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf_path = \"Research_Papers/paper1.pdf\"\n",
    "# pdf_file = open(pdf_path, 'rb')\n",
    "# reader = PyPDF2.PdfReader(pdf_file)\n",
    "# page = reader.getPage(0)\n",
    "# text = page.extract_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d46bd45a-645f-45d0-946d-0a5292361f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"Provide keywords, authors, and other metadata information in a list.\"\n",
    "# context = text\n",
    "# messages = [\n",
    "#     {\"role\": \"system\", \"content\": \"You are a chatbot who creates metadata based on the provided context.\"},\n",
    "#     {\"role\": \"system\", \"content\": {context}},\n",
    "#     {\"role\": \"user\", \"content\": {query}},\n",
    "# ]\n",
    "# start_time = time.time()\n",
    "# response = get_llama3_chat_reponse(messages)\n",
    "# print(response)\n",
    "# print(\"--- %.2f seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "897a0cba-0849-4e40-85b6-4338cd0fe188",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting text from Research_Papers\\paper01.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "C:\\Users\\justinfz\\AppData\\Local\\anaconda3\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:649: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting text from Research_Papers\\paper02.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting text from Research_Papers\\paper03.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting text from Research_Papers\\paper04.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting text from Research_Papers\\paper05.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting text from Research_Papers\\paper06.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting text from Research_Papers\\paper07.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting text from Research_Papers\\paper08.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting text from Research_Papers\\paper09.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting text from Research_Papers\\paper10.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting text from Research_Papers\\paper11.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting text from Research_Papers\\paper12.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting text from Research_Papers\\paper13.pdf\n",
      "--- 106.50 seconds ---\n"
     ]
    }
   ],
   "source": [
    "pdf_dir = \"Research_Papers\"\n",
    "start_time = time.time()\n",
    "metadatas = []\n",
    "file_number = 1\n",
    "for filename in os.listdir(pdf_dir):\n",
    "    if (not filename.endswith('.pdf')):\n",
    "        continue\n",
    "    chunks = []\n",
    "    collection = chroma_client.create_collection(\n",
    "        name=(\"paper\" + f'{file_number:02d}'),\n",
    "        metadata={\"hnsw:space\": \"cosine\"}\n",
    "    )\n",
    "    \n",
    "    pdf_path = os.path.join(pdf_dir, filename)\n",
    "    print(f\"Extracting text from {pdf_path}\")\n",
    "    pdf_file = open(pdf_path, 'rb')\n",
    "    \n",
    "    # Create a PDF reader object\n",
    "    reader = PyPDF2.PdfReader(pdf_file)\n",
    "    first_page = reader.getPage(0).extract_text()\n",
    "    query = \"Provide keywords, authors, and other metadata information in a list.\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a chatbot who creates metadata based on the provided context.\"},\n",
    "        {\"role\": \"system\", \"content\": {first_page}},\n",
    "        {\"role\": \"user\", \"content\": {query}},\n",
    "    ]\n",
    "    response = get_llama3_chat_reponse(messages)\n",
    "    metadatas.append(response)\n",
    "    # Iterate through each page\n",
    "    for page_num in range(reader.getNumPages()):\n",
    "        # Get the page\n",
    "        page = reader.getPage(page_num)\n",
    "        \n",
    "        # Extract text from the page\n",
    "        text = page.extract_text()\n",
    "        \n",
    "        # Store the text in the dictionary with the page number as the key\n",
    "        chunks.append(text)\n",
    "        \n",
    "    chunk_embeddings = embedding_model.encode(chunks, normalize_embeddings=True)\n",
    "    collection.upsert(\n",
    "    embeddings = chunk_embeddings,\n",
    "    documents=chunks,\n",
    "    ids= [str(i) for i in range(len(chunks))]\n",
    "    )\n",
    "    # Close the PDF file\n",
    "    pdf_file.close()\n",
    "    file_number += 1\n",
    "\n",
    "print(\"--- %.2f seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8906e5e-1cbe-4689-9be9-dca4042ee0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2', cache_folder = '/data/base_models')\n",
    "# chunk_embeddings = embedding_model.encode(chunks)\n",
    "# chunk_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb11b155-c32c-4db2-b1cf-80b00e761237",
   "metadata": {},
   "source": [
    "## Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1217d641-b546-4b4f-8e4e-ee7a45f9c12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant\n",
      "\n",
      "Here is the metadata information extracted from the provided context:\n",
      "\n",
      "**Metadata Information:**\n",
      "\n",
      "* **Keywords:** Fault detection, knowledge distillation, multiple failure modes, cross fault mode\n",
      "* **Authors:** Jinghao Zheng, Chongdang Liu, Linxuan Zhang\n",
      "* **Title:** Cross-Modal Knowledge Distillation for Fault Detection under Multiple Failure Modes\n",
      "* **Conference:** China Automation Congress (CAC)\n",
      "* **Year:** 2021\n",
      "* **DOI:** 10.1109/CAC53003.2021.9728306\n",
      "* **Publisher:** IEEE\n",
      "* **ISBN:** 978-1-6654-2647-3\n",
      "* **License:** Authorized licensed use limited to: University of Maryland College Park. Downloaded on September 08, 2023 at 05:39:04 UTC from IEEE Xplore. Restrictions apply.\n"
     ]
    }
   ],
   "source": [
    "print(metadatas[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40d64f9a-d1eb-43e8-ac10-ce373311c0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_collection = chroma_client.create_collection(name=\"metadata\", metadata={\"hnsw:space\": \"cosine\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "244c2a2a-28de-419e-9ba2-d8a6e1fd4245",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_embeddings = embedding_model.encode(metadatas)\n",
    "metadata_collection.add(\n",
    "    embeddings = metadata_embeddings,\n",
    "    documents = metadatas,\n",
    "    ids = [f'paper{i:02d}' for i in range(1, len(metadatas)+1)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8b22f3ff-a742-48f7-a0ca-d6b09e8dec76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids': [['paper03', 'paper11']], 'distances': [[0.5564844608306885, 0.5907408595085144]], 'metadatas': [[None, None]], 'embeddings': None, 'documents': [[\"assistant\\n\\nHere is the metadata information extracted from the provided text:\\n\\n**Keywords:**\\n\\n* Remaining Useful Life (RUL) estimation\\n* Abrupt failures\\n* Data-driven approaches\\n* Long Short Term Memory (LSTM) neural network\\n* Prognostics and health management systems\\n* Condition-based maintenance\\n* System degradation\\n* Machine learning\\n\\n**Authors:**\\n\\n* Wei Huang\\n* Hamed Khorasgani\\n* Chetan Gupta\\n* Ahmed Farahat\\n* Shuai Zheng\\n\\n**Journal/Conference:**\\n\\n* Industrial AI Laboratory, Hitachi America Ltd.\\n\\n**Year:**\\n\\n* 2018\\n\\n**Paper Title:**\\n\\n* Remaining Useful Life Estimation for Systems with Abrupt Failures\\n\\n**Abstract:**\\n\\n* A brief summary of the paper's main contributions and findings.\\n\\n**Categories:**\\n\\n* Artificial Intelligence\\n* Machine Learning\\n* Predictive Maintenance\\n* Condition-Based Maintenance\\n* Prognostics and Health Management\\n\\nLet me know if you'd like me to add or modify any of this metadata!\", 'assistant\\n\\nHere is the metadata information extracted from the provided text:\\n\\n**Metadata Information:**\\n\\n* **Title:** Challenges and Opportunities of System-Level Prognostics\\n* **Authors:**\\n\\t+ Seokgoo Kim\\n\\t+ Joo-Ho Choi\\n\\t+ Nam H. Kim\\n* **Journal:** Sensors\\n* **Volume:** 21\\n* **Pages:** 7655\\n* **Year:** 2021\\n* **DOI:** 10.3390/s21227655\\n* **Keywords:** system-level prognostics, performance, remaining useful life, dependency, multiple components, challenges\\n* **Abstract:** A review of approaches for system-level prognostics, including health index-based, component RUL-based, influenced component-based, and multiple failure mode-based prognostics.\\n* **Citation:** Kim, S.; Choi, J.-H.; Kim, N.H. Challenges and Opportunities of System-Level Prognostics. Sensors 2021, 21, 7655. https://doi.org/10.3390/s21227655\\n* **Publisher:** MDPI\\n* **License:** Creative Commons Attribution (CC BY) license\\n* **Received:** 22 October 2021\\n* **Accepted:** 16 November 2021\\n* **Published:** 18 November 2021']], 'uris': None, 'data': None}\n",
      "assistant\n",
      "\n",
      "Here is the metadata information extracted from the provided text:\n",
      "\n",
      "**Keywords:**\n",
      "\n",
      "* Remaining Useful Life (RUL) estimation\n",
      "* Abrupt failures\n",
      "* Data-driven approaches\n",
      "* Long Short Term Memory (LSTM) neural network\n",
      "* Prognostics and health management systems\n",
      "* Condition-based maintenance\n",
      "* System degradation\n",
      "* Machine learning\n",
      "\n",
      "**Authors:**\n",
      "\n",
      "* Wei Huang\n",
      "* Hamed Khorasgani\n",
      "* Chetan Gupta\n",
      "* Ahmed Farahat\n",
      "* Shuai Zheng\n",
      "\n",
      "**Journal/Conference:**\n",
      "\n",
      "* Industrial AI Laboratory, Hitachi America Ltd.\n",
      "\n",
      "**Year:**\n",
      "\n",
      "* 2018\n",
      "\n",
      "**Paper Title:**\n",
      "\n",
      "* Remaining Useful Life Estimation for Systems with Abrupt Failures\n",
      "\n",
      "**Abstract:**\n",
      "\n",
      "* A brief summary of the paper's main contributions and findings.\n",
      "\n",
      "**Categories:**\n",
      "\n",
      "* Artificial Intelligence\n",
      "* Machine Learning\n",
      "* Predictive Maintenance\n",
      "* Condition-Based Maintenance\n",
      "* Prognostics and Health Management\n",
      "\n",
      "Let me know if you'd like me to add or modify any of this metadata!\n",
      "\n",
      "assistant\n",
      "\n",
      "Here is the metadata information extracted from the provided text:\n",
      "\n",
      "**Metadata Information:**\n",
      "\n",
      "* **Title:** Challenges and Opportunities of System-Level Prognostics\n",
      "* **Authors:**\n",
      "\t+ Seokgoo Kim\n",
      "\t+ Joo-Ho Choi\n",
      "\t+ Nam H. Kim\n",
      "* **Journal:** Sensors\n",
      "* **Volume:** 21\n",
      "* **Pages:** 7655\n",
      "* **Year:** 2021\n",
      "* **DOI:** 10.3390/s21227655\n",
      "* **Keywords:** system-level prognostics, performance, remaining useful life, dependency, multiple components, challenges\n",
      "* **Abstract:** A review of approaches for system-level prognostics, including health index-based, component RUL-based, influenced component-based, and multiple failure mode-based prognostics.\n",
      "* **Citation:** Kim, S.; Choi, J.-H.; Kim, N.H. Challenges and Opportunities of System-Level Prognostics. Sensors 2021, 21, 7655. https://doi.org/10.3390/s21227655\n",
      "* **Publisher:** MDPI\n",
      "* **License:** Creative Commons Attribution (CC BY) license\n",
      "* **Received:** 22 October 2021\n",
      "* **Accepted:** 16 November 2021\n",
      "* **Published:** 18 November 2021\n"
     ]
    }
   ],
   "source": [
    "query = \"What are the two types of models for prognostics?\"\n",
    "results = metadata_collection.query(\n",
    "    query_embeddings = embedding_model.encode(query).tolist(),\n",
    "    n_results=2\n",
    "    )\n",
    "print(results)\n",
    "context = '\\n\\n'.join(results['documents'][0])\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd99172-1dc8-44f5-a66c-c2a7c82b38f0",
   "metadata": {},
   "source": [
    "## Retrieving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4325b7a0-a0bb-4256-9133-d87382aaa321",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_vector_db(query):\n",
    "    results = []\n",
    "    metadata_results = metadata_collection.query(\n",
    "    query_embeddings = embedding_model.encode(query).tolist(),\n",
    "    n_results=2\n",
    "    )\n",
    "    for id in metadata_results['ids'][0]:\n",
    "        collection = chroma_client.get_collection(name=id)\n",
    "        doc_results = collection.query(\n",
    "        query_embeddings = embedding_model.encode(query).tolist(),\n",
    "        n_results=2\n",
    "        )\n",
    "        for distance in doc_results['distances'][0]:\n",
    "            if distance < 0.8:\n",
    "                new_data = doc_results\n",
    "                results.append(new_data)\n",
    "    # return '\\n\\n'.join(results[0])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ec0fd60a-474b-4c75-8248-99fd6f9601e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_vector_db(query, n_results=2):\n",
    "    return collection.query(\n",
    "    query_embeddings = embedding_model.encode(query).tolist(),\n",
    "    n_results=n_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f720231f-8835-442a-8cc4-c4650e933bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids': [['1', '4']], 'distances': [[0.6661484837532043, 0.7068995237350464]], 'metadatas': [[None, None]], 'embeddings': None, 'documents': [['186 IEEE TRANSACTIONS ON SEMICONDUCTOR MANUFACTURING, VOL. 34, NO. 2, MAY 2021\\nof expertise knowledge about the physics-of-failure, hold\\npotential to learn the degradation patterns from the time seriessensor data and provide accurate TTF predictions. This study\\naims to develop an effective data-driven prognostic approach\\nthat can achieve reliable multi-mode failure predictions withmulti-sensor data collected from the IME process.\\nDespite recent advances in data-driven prognostics, there\\nare still two challenging issues in fault prognosis of IME pro-cess: 1) the inherent data discrepancy among different tools.\\nIn IME process, the sensor data collected from different tools\\nmay have certain distribution discrepancy due to their vari-ous operating conditions or settings, which makes it difﬁcult\\nto generalize the learned prognostic knowledge from some\\ntools to the others. 2) data imbalance due to multiple coexist-\\ning failure modes. There are multiple different failure modes\\nin the IME process, and sometimes certain types of faultsrarely occur, so there is less failure data that can be col-\\nlected. Basically, it is challenging to accurately perform failure\\nprediction with insufﬁcient monitoring data via data-drivenmethods.\\nThe above two issues have a great impact on the effec-\\ntiveness of the data-driven prognostic methods. To addressthese challenges, this article proposes a novel two-stage trans-\\nfer learning approach for fault prognosis of IME process. The\\nﬁrst-stage transfer learning is performed to handle a selectedsingle fault mode, where an unsupervised domain adapta-\\ntion technique is used to align the distributions of features\\nacross the various IME tools via domain-adversarial learn-ing. Hence, tool-invariant features can be extracted and the\\ndata distribution discrepancy can be bridged, which beneﬁts\\nthe generalization of the deep model. Besides, the temporal\\nconvolutional network (TCN) is embedded to learn temporal\\nrepresentations from time-series sensor data. Next, the second-stage transfer learning is carried out to transfer the degradation\\nknowledge from one certain fault mode to others by using the\\nwell-trained deep model in the ﬁrst stage as pretrained model.Herein, only small amount of sensor data is required to ﬁne-\\ntuning this model, which mitigates the issue of insufﬁcient\\ndata in other fault modes.\\nThe remainder of this article starts with the related works\\nin Section II. The preliminaries of deep learning model are\\nprovided in Section III. The details of the proposed two-stage transfer learning method are presented in Section IV ,\\nand experimental results and analysis are given in Section V .\\nConclusions including perspectives for future work are drawnin Section VI.\\nII. R\\nELATED WORKS\\nA. Deep Learning-Based Prognostics in IME Process\\nIn recent years, intelligent data-driven prognostic\\napproaches have been successfully developed in semi-\\nconductor manufacturing [2]–[4]. Especially, deep learninghas been emerging as a highly efﬁcient technique in fault\\nprognosis due to its great advantages in feature representation,\\nhigh nonlinear mapping as well as the potential to handle bigdata [5]. Among those deep learning methods, deep Recurrent\\nNeural Networks (RNNs) based on gate mechanism such aslong-short term memory (LSTM) [6] and gated recurrent unit\\n(GRU) have been widely used for fault prognosis [7]. Heand Jin proposed a prognostic framework for IME process,\\nwhere LSTM network was used to predict the time-to-failure\\nof the ﬂowcool components [1]. Vishnu et al. proposed a\\ndeep RNN-based method with ensemble of LSTM networks\\nto learn an enhanced model for failure prediction of three\\ntypes of failure modes in IME systems [8]. In addition,Baiet al. [9] proposed a novel generic temporal convolutional\\nnetwork (TCN) architecture for sequence modeling, which\\nhas been demonstrated to be effective and simpler on abroad range of sequence modeling tasks compared with the\\ncanonical recurrent architectures such as LSTMs and GRUs.\\nA novel prognostic approach that applied TCNs for direct\\nfeature learning was developed to obtain a light and effective\\nprognostic model, and promising prediction results were alsoachieved [10], which demonstrates that TCNs hold potential\\nto be used in building an efﬁcient deep learning model for\\nintelligent fault prognosis. In addition, in order to obtain awell-trained deep model, the metrics called loss functions\\nplay an important role in guiding the training process, such\\nas mean squared error (MSE) for regression tasks. For faultprognosis, sometimes it is necessary to penalize solutions that\\nproudce late RUL predictions, in that they increase safety\\nrisks. For instance, an asymmetric scoring function in [11]was proposed to evaluate the performance of RUL prediction\\nfor turbine engines, where the late predictions are more heav-\\nily penalized than early predictions. Rengasamy et al. [12]\\nstudied the effect of several MSE-based asymmetric loss\\nfunctions on RUL predictions of turbine engines, which\\ndemonstrated that the prediction performance were improved\\nby using deep learning models with asymmetrical loss\\nfunctions. In this work, a weighted MSE metric is designedto put more emphasis on the time points that approach failure\\nduring the training process of proposed deep model, which\\nmatchs the scenario of TTF prediction in IME process.\\nIn semiconductor manufacturing, many fault detection and\\nclassiﬁcation (FDC) tasks have beneﬁted greatly from deep\\nlearning techniques and achieved promising results for healthmonitoring [13]–[15], while limited studies can be found in\\nthe literature on developing deep learning-based prognostic\\nmethods. Moreover, though deep learning models such asdeep RNNs are powerful in representation learning, most exist\\neffective deep learning-based prognostic methods assume that\\ntraining and testing data have the same distribution and a largeamount of sensor data are available for the training process.\\nIME is an advanced manufacturing technology that requires\\nintelligent prognosis to improve its operational stability andproduction efﬁciency. As mentioned in introduction section,\\nthere are two challenging issues that require sufﬁcient atten-\\ntion. To meet the amount of data required to train a deep\\nmodel, more sensor data can be collected from many different\\ntools, but the distribution discrepancy of the data from vari-ous tools remains a challenge for feature learning, which is\\nstill an open issue. Besides, sensor data of some uncommon\\nfailure modes in the ﬂowcool system result in lack of faultinformation, making it difﬁcult to train deep learning model\\nfor accurate failure prediction. Transfer learning techniques\\nAuthorized licensed use limited to: University of Maryland College Park. Downloaded on September 08,2023 at 05:33:43 UTC from IEEE Xplore.  Restrictions apply. ', 'LIU et al. : TWO-STAGE TRANSFER LEARNING FOR FAULT PROGNOSIS OF IME PROCESS 189\\nloss function:\\nLd/parenleftbig\\nθf,θd/parenrightbig\\n=−1\\nN/summationdisplay\\nxi∈Ds∪DtM/summationdisplay\\nj=11{mi=j}·log/parenleftbig\\npi,j/parenrightbig\\n,(5)\\nwhere (xi,mi)represent the i-th data example and the related\\ntool label, Mis the number of tools, and pi,j=Gd(Gf(xi))is\\nthe probability of classify xito class j.\\nBesides, based on the features extracted by TCN, a regres-\\nsion model Gycomposed of several fully connected (FC)\\nlayers is adopted to predict the TTFs under source supervi-sion. It should be mentioned that, instead of most regression\\nmethods using mean squared error (MSE) as the loss func-\\ntion, this work designs a weighted MSE metric that puts moreemphasis on the time points approaching failure. The weight\\nw\\nicorresponding to the true label yiis deﬁned as:\\nwi=2M−m,ifm−1\\nM<yi<m\\nM,n=1,2,..., M,(6)\\nwhere Mdenotes the number of intervals with different\\nweights. Therefore, the regression loss is given as below,\\nLy/parenleftbig\\nθf,θy/parenrightbig\\n=1\\nNs/summationdisplay\\nxi∈Dswi·/parenleftbig\\nGy/parenleftbig\\nGf(xi)/parenrightbig\\n−yi/parenrightbig2. (7)\\nAccording to [18], this optimization problem can be\\nregarded as a minmax problem and solved by searching for asaddle point, and the learned parameters in the network can\\nbe updated using gradient-based method as the form:\\nθ\\nf←θf−μ/parenleftbigg∂Ly\\n∂θf−λ∂Ld\\n∂θf/parenrightbigg\\n, (8)\\nθy←θy−μ/parenleftbigg∂Ly\\n∂θy/parenrightbigg\\n, (9)\\nθd←θd−μ/parenleftbigg∂Ld\\n∂θd/parenrightbigg\\n. (10)\\nWe use stochastic estimates of the updates in Eqs. (9)-(11)\\nvia SGD and its variants, where the learning rate μrep-\\nresents the learning steps taken by the SGD algorithm astraining progresses. In this way, the whole deep model can be\\nefﬁciently trained end-to-end by back-propagation, using the\\nauto-differentiation technique. Adam optimizer [23] is used tooptimize the learning process.\\nB. Proposed Prognosis Framework\\nThis article proposes a two-stage transfer learning-based\\nprognostic method for multiple fault modes scenario of the\\nIME process. The prognosis framework on the basis of TCN-\\nDANN is presented in Fig. 4, which can be summarized asthe following two stages.\\n1) The ﬁrst stage is the intra domain adaptation, all the fault\\nmodes are evaluated and one of them will be picked\\nup to build the base TCN-DANN model. Adversarial\\nlearning is applied to align the sensor data from differenttools under the identiﬁed fault mode, herein bridging\\nthe distribution discrepancy caused by varying operating\\nconditions of different tools.\\n2) The second stage is to transfer knowledge from the base\\nfault mode to the other ones that provide much less\\nFig. 4. Framework of the proposed two-stage transfer learning-based fault\\nprognosis for IME process. Stage 1: using domain-adversarial learning for the\\nbase fault mode; Stage 2: ﬁne-tuning the pretrained TCN-DANN model forother fault modes.\\nCM data. The above well-trained TCN-DANN model is\\nadopted as the pretrained deep model, and less amount of\\nCM data from other fault modes is used to ﬁne-tune the\\nmodel. Then fault prognostic model extended to other\\nfault modes can be effectively and swiftly constructed.\\nBefore presenting experimental studies on the IME datasets,\\nwe note a few remarks on the proposed framework: 1) Unlike\\nthe domain adaptation methods that reduce the distribution\\ndiscrepancy through minimizing some metrics such as KLdivergence and MMD [17], [24], the utilization of DANN\\nin the proposed method introduces adversarial learning to\\ncombine the data alignment and parameter optimization viaback-propagation, which improves the training efﬁciency. 2) In\\ncontrast to the DANN with a binary domain classiﬁer that\\nbridge the distribution discrepancy between source and tar-get domain, our method adopts a multi-class domain classiﬁer\\nthat is capable of aligning the features of multiple tools in a\\nmore ﬁne-grained way. 3) The cross-FM (fault modes) transferlearning in the second stage applies the deep model from the\\nbase fault mode with relatively richer information as a pre-\\ntrained model, thus much less data examples will be requiredto ﬁne-tune it and achieves faster and accurate prognosis\\nresults.\\nIn the proposed deep architecture, dropout technique [25]\\nis adopted as an effective regularization strategy in the\\nTCN blocks to avoid overﬁtting. The rectiﬁed linear units(ReLU) and sigmoid are used as the activation functions\\nin convolutional and FC layers. Bayesian optimization algo-\\nrithm (BOA) is adopted for model selection, i.e., optimiz-ing some key hyper-parameters of the deep network. We\\nselect these hyper-parameters via cross validation with tree\\nAuthorized licensed use limited to: University of Maryland College Park. Downloaded on September 08,2023 at 05:33:43 UTC from IEEE Xplore.  Restrictions apply. ']], 'uris': None, 'data': None}\n"
     ]
    }
   ],
   "source": [
    "query = \"What are the two types of models for prognostics?\"\n",
    "retrieved_results = retrieve_vector_db(query)\n",
    "print(retrieved_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa4e529-12cf-4d4a-886a-6a513765aaae",
   "metadata": {},
   "source": [
    "## Answer Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe185dbb-262f-4a1d-ad73-adcbbf0f55a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     model_id,\n",
    "#     torch_dtype=torch.bfloat16,\n",
    "#     device_map=\"auto\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df275835-e215-446c-8ec3-1a614169bbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# terminators = [\n",
    "#     tokenizer.eos_token_id,\n",
    "#     tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "# ]\n",
    "# def get_llama3_chat_reponse(messages):\n",
    "#     input_ids = tokenizer.apply_chat_template(\n",
    "#     messages,\n",
    "#     return_tensors=\"pt\").to(model.device)\n",
    "#     outputs = model.generate(\n",
    "#     input_ids,\n",
    "#     max_new_tokens=500,\n",
    "#     eos_token_id=terminators,\n",
    "#     do_sample=True,\n",
    "#     temperature=0.01,\n",
    "#     top_p=0.9,)\n",
    "#     response = outputs[0][input_ids.shape[-1]:]\n",
    "#     return (tokenizer.decode(response, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd48653-fda0-43a7-bed8-6e6b3fe972c9",
   "metadata": {},
   "source": [
    "## RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "c47a504e-27c7-40cf-ab51-9bcc1da19e77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant\n",
      "\n",
      "One-hot encoding produces binary vectors where all elements are 0, except for one element which is 1. The position of the 1 element corresponds to the class or category that the original value represents.\n",
      "\n",
      "For example, if you have a categorical variable with three classes: A, B, and C, the one-hot encoding would produce the following vectors:\n",
      "\n",
      "* For A: [1, 0, 0]\n",
      "* For B: [0, 1, 0]\n",
      "* For C: [0, 0, 1]\n",
      "\n",
      "In this example, the binary vector has three elements, and only one element is 1, which corresponds to the class that the original value represents.\n",
      "--- 5.56 seconds ---\n"
     ]
    }
   ],
   "source": [
    "query = \"What kind of vectors does one-hot encoding produce?\"\n",
    "retrieved_results = retrieve_vector_db(query)\n",
    "context = '\\n\\n'.join(retrieved_results['documents'][0])\n",
    "# context = '\\n\\n'.join(retrieved_results[0])\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a chatbot who gives an answer strictly based on the content provided\"},\n",
    "    {\"role\": \"system\", \"content\": {context}},\n",
    "    {\"role\": \"user\", \"content\": {query}},\n",
    "]\n",
    "start_time = time.time()\n",
    "response = get_llama3_chat_reponse(messages)\n",
    "print(response)\n",
    "print(\"--- %.2f seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab14712-74dc-4d4e-b460-948a29480da7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# query = \"What are the two types of models for prognostics?\"\n",
    "# retrieved_results = retrieve_vector_db(query)\n",
    "# pairs = []\n",
    "# for i in retrieved_results['documents'][0]:\n",
    "#     pairs.append([query, i])\n",
    "# with torch.no_grad():\n",
    "#     inputs = rerank_tokenizer(pairs, padding=True, truncation=True, return_tensors='pt', max_length=512)\n",
    "#     scores = rerank_model(**inputs, return_dict=True).logits.view(-1, ).float()\n",
    "# numbers = scores.tolist()\n",
    "# numbers_array = np.array(numbers)\n",
    "# indices = np.argsort(numbers_array)[-2:][::-1]\n",
    "# results = [pairs[i][1] for i in indices.tolist()]\n",
    "# context = '\\n\\n'.join(results)\n",
    "# messages = [\n",
    "#     {\"role\": \"system\", \"content\": \"You are a chatbot who gives an answer and confidence score out of 100 based on the content provided\"},\n",
    "#     {\"role\": \"system\", \"content\": {context}},\n",
    "#     {\"role\": \"user\", \"content\": {query}},\n",
    "# ]\n",
    "# start_time = time.time()\n",
    "# response = get_llama3_chat_reponse(messages)\n",
    "# print(response)\n",
    "# print(\"--- %.2f seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d05f9d4-016b-41ce-8ca6-e9041c551221",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a602a8b-3a8a-4087-a9ab-de9b2aeff1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "[int(s) for s in re.findall(r'\\b\\d+\\b', response)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f7796e-807f-4a35-958e-deaebf9e9f41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
